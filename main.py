from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Optional
import re
import io
from pathlib import Path

# File processing imports
try:
    import PyPDF2
except ImportError:
    PyPDF2 = None

try:
    from docx import Document
except ImportError:
    Document = None


# ==================== PYDANTIC MODELS ====================

class AnalysisResponse(BaseModel):
    """Response model for resume analysis"""
    ats_score: float = Field(..., ge=0, le=100, description="ATS compatibility score")
    keyword_match: float = Field(..., ge=0, le=100, description="Keyword match percentage")
    skill_match: float = Field(..., ge=0, le=100, description="Skill match percentage")
    semantic_similarity: float = Field(..., ge=0, le=100, description="Semantic similarity score")
    matched_skills: List[str] = Field(default_factory=list, description="Skills found in resume")
    missing_skills: List[str] = Field(default_factory=list, description="Skills missing from resume")
    suggestions: List[str] = Field(default_factory=list, description="Improvement suggestions")
    resume_bullets: List[str] = Field(default_factory=list, description="Original bullet points")
    improved_bullets: List[str] = Field(default_factory=list, description="Improved bullet points")


# ==================== FASTAPI APP SETUP ====================

app = FastAPI(
    title="ResumeLens API",
    description="AI-powered resume analysis and ATS optimization",
    version="1.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://127.0.0.1:5500"],  # frontend
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ==================== CONFIGURATION ====================

MAX_FILE_SIZE = 5 * 1024 * 1024  # 5MB
ALLOWED_EXTENSIONS = {".pdf", ".docx", ".txt"}

# Comprehensive skill database
SKILLS_DATABASE = {
    # Programming Languages
    "python", "javascript", "java", "c++", "c#", "ruby", "go", "rust", "swift",
    "kotlin", "php", "typescript", "scala", "r", "matlab",
    
    # Web Technologies
    "html", "css", "react", "angular", "vue", "nodejs", "express", "django",
    "flask", "fastapi", "spring", "asp.net", "jquery", "bootstrap", "tailwind",
    
    # Databases
    "sql", "mysql", "postgresql", "mongodb", "redis", "elasticsearch", "cassandra",
    "dynamodb", "oracle", "sqlite", "mariadb",
    
    # Cloud & DevOps
    "aws", "azure", "gcp", "docker", "kubernetes", "jenkins", "gitlab", "github",
    "terraform", "ansible", "circleci", "travis ci",
    
    # Data Science & ML
    "machine learning", "deep learning", "tensorflow", "pytorch", "keras",
    "scikit-learn", "pandas", "numpy", "matplotlib", "seaborn", "nltk", "spacy",
    "opencv", "neural networks",
    
    # Tools & Frameworks
    "git", "jira", "confluence", "slack", "agile", "scrum", "kanban",
    "rest api", "graphql", "microservices", "ci/cd", "tdd", "unit testing",
    
    # Soft Skills
    "leadership", "communication", "teamwork", "problem solving", "analytical",
    "project management", "time management", "collaboration", "presentation",
}

# Action verbs for bullet point improvements
ACTION_VERBS = [
    "Developed", "Implemented", "Designed", "Led", "Managed", "Architected",
    "Built", "Created", "Optimized", "Improved", "Achieved", "Delivered",
    "Spearheaded", "Engineered", "Established", "Executed"
]


# ==================== FILE PROCESSING ====================

def extract_text_from_pdf(file_bytes: bytes) -> str:
    """Extract text from PDF file"""
    if PyPDF2 is None:
        raise HTTPException(status_code=500, detail="PDF processing library not installed")
    
    try:
        pdf_file = io.BytesIO(file_bytes)
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text.strip()
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Failed to parse PDF: {str(e)}")


def extract_text_from_docx(file_bytes: bytes) -> str:
    """Extract text from DOCX file"""
    if Document is None:
        raise HTTPException(status_code=500, detail="DOCX processing library not installed")
    
    try:
        docx_file = io.BytesIO(file_bytes)
        doc = Document(docx_file)
        text = "\n".join([paragraph.text for paragraph in doc.paragraphs])
        return text.strip()
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Failed to parse DOCX: {str(e)}")


def extract_text_from_file(file_bytes: bytes, filename: str) -> str:
    """Extract text based on file extension"""
    extension = Path(filename).suffix.lower()
    
    if extension == ".pdf":
        return extract_text_from_pdf(file_bytes)
    elif extension == ".docx":
        return extract_text_from_docx(file_bytes)
    elif extension == ".txt":
        try:
            return file_bytes.decode('utf-8')
        except UnicodeDecodeError:
            raise HTTPException(status_code=400, detail="Invalid text file encoding")
    else:
        raise HTTPException(status_code=400, detail=f"Unsupported file type: {extension}")


# ==================== RESUME ANALYSIS ====================

def extract_skills(text: str) -> List[str]:
    """Extract skills from resume text"""
    text_lower = text.lower()
    found_skills = []
    
    for skill in SKILLS_DATABASE:
        # Use word boundaries for accurate matching
        pattern = r'\b' + re.escape(skill) + r'\b'
        if re.search(pattern, text_lower):
            found_skills.append(skill.title())
    
    return sorted(set(found_skills))


def extract_bullets(text: str) -> List[str]:
    """Extract bullet points from resume"""
    bullets = []
    lines = text.split('\n')
    
    for line in lines:
        line = line.strip()
        # Match lines starting with bullet characters or action verbs
        if line and (line.startswith('â€¢') or line.startswith('-') or line.startswith('*')):
            bullets.append(line.lstrip('â€¢-* ').strip())
        elif line and any(line.startswith(verb) for verb in ACTION_VERBS):
            bullets.append(line)
    
    # Return first 3 bullets for display
    return bullets[:3] if bullets else ["Contributed to team projects", "Worked on various tasks", "Assisted with daily operations"]


def improve_bullet(original: str) -> str:
    """Generate improved version of a bullet point"""
    # Check if bullet already has metrics
    has_metric = bool(re.search(r'\d+%|\d+x|\d+ [a-z]+', original.lower()))
    has_action_verb = any(original.startswith(verb) for verb in ACTION_VERBS)
    
    improved = original
    
    # Add action verb if missing
    if not has_action_verb:
        import random
        improved = f"{random.choice(ACTION_VERBS)} {improved.lower()}"
    
    # Add metric if missing
    if not has_metric:
        metrics = [
            "by 25%", "by 40%", "by 30%", "reducing time by 35%",
            "improving efficiency by 45%", "increasing performance by 20%"
        ]
        import random
        improved += f", {random.choice(metrics)}"
    
    # Add impact/result if too short
    if len(improved.split()) < 10:
        impacts = [
            "resulting in improved team productivity",
            "leading to enhanced system performance",
            "contributing to successful project delivery",
            "enabling better stakeholder communication"
        ]
        import random
        improved += f" {random.choice(impacts)}"
    
    return improved


def calculate_ats_score(resume_text: str) -> float:
    """Calculate ATS compatibility score"""
    score = 50.0  # Base score
    
    # Check for sections
    sections = ["experience", "education", "skills", "projects"]
    for section in sections:
        if section in resume_text.lower():
            score += 8
    
    # Check for proper formatting indicators
    if len(resume_text) > 200:
        score += 5
    if resume_text.count('\n') > 10:
        score += 5
    
    # Check for contact info
    if re.search(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', resume_text):
        score += 5
    if re.search(r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b', resume_text):
        score += 5
    
    return min(score, 100.0)


def analyze_resume(resume_text: str, job_description: Optional[str] = None) -> AnalysisResponse:
    """Perform comprehensive resume analysis"""
    
    # Extract skills from resume
    resume_skills = extract_skills(resume_text)
    
    # Extract skills from job description if provided
    job_skills = extract_skills(job_description) if job_description else []
    
    # Calculate matched and missing skills
    matched_skills = [skill for skill in resume_skills if skill.lower() in [s.lower() for s in job_skills]] if job_skills else resume_skills[:6]
    missing_skills = [skill for skill in job_skills if skill.lower() not in [s.lower() for s in resume_skills]] if job_skills else ["Docker", "Kubernetes", "AWS", "React"]
    
    # Calculate scores
    ats_score = calculate_ats_score(resume_text)
    
    if job_skills:
        skill_match = (len(matched_skills) / len(job_skills) * 100) if job_skills else 0
        keyword_match = min(skill_match + 10, 100)
    else:
        skill_match = 75.0
        keyword_match = 70.0
    
    semantic_similarity = (ats_score + skill_match) / 2
    
    # Extract and improve bullets
    resume_bullets = extract_bullets(resume_text)
    improved_bullets = [improve_bullet(bullet) for bullet in resume_bullets]
    
    # Generate suggestions
    suggestions = [
        f"âœ… Good match! {len(matched_skills)} skills found in resume." if matched_skills else "âš ï¸ Consider adding more relevant skills.",
    ]
    
    if missing_skills:
        suggestions.append(f"Add these skills: {', '.join(missing_skills[:4])}")
    
    suggestions.extend([
        "Use strong action verbs like 'Developed', 'Led', 'Achieved'",
        "Quantify achievements with numbers and metrics",
        "Highlight leadership and impact in projects",
        "Ensure consistent formatting throughout resume"
    ])
    
    return AnalysisResponse(
        ats_score=round(ats_score, 1),
        keyword_match=round(keyword_match, 1),
        skill_match=round(skill_match, 1),
        semantic_similarity=round(semantic_similarity, 1),
        matched_skills=matched_skills[:10],
        missing_skills=missing_skills[:6],
        suggestions=suggestions,
        resume_bullets=resume_bullets,
        improved_bullets=improved_bullets
    )


# ==================== API ENDPOINTS ====================

@app.get("/")
async def root():
    """Health check endpoint"""
    return {
        "status": "online",
        "service": "ResumeLens API",
        "version": "1.0.0",
        "endpoints": ["/analyze", "/health"]
    }


@app.get("/health")
async def health_check():
    """Health check for monitoring"""
    return {"status": "healthy"}


@app.post("/analyze", response_model=AnalysisResponse)
async def analyze_resume_endpoint(
    resume: UploadFile = File(..., description="Resume file (PDF, DOCX, or TXT)"),
    job_description: Optional[str] = Form(None, description="Optional job description")
):
    """
    Analyze resume against optional job description
    
    - **resume**: Upload resume file (PDF, DOCX, TXT)
    - **job_description**: Optional job description text for matching
    
    Returns comprehensive analysis including:
    - ATS compatibility score
    - Skill matching analysis
    - Improvement suggestions
    - Enhanced bullet points
    """
    
    # Validate file extension
    file_extension = Path(resume.filename).suffix.lower()
    if file_extension not in ALLOWED_EXTENSIONS:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid file type. Allowed types: {', '.join(ALLOWED_EXTENSIONS)}"
        )
    
    # Read file content
    file_bytes = await resume.read()
    
    # Validate file size
    if len(file_bytes) > MAX_FILE_SIZE:
        raise HTTPException(
            status_code=400,
            detail=f"File size exceeds maximum limit of {MAX_FILE_SIZE / (1024*1024)}MB"
        )
    
    # Check if file is empty
    if len(file_bytes) == 0:
        raise HTTPException(status_code=400, detail="Uploaded file is empty")
    
    try:
        # Extract text from file
        resume_text = extract_text_from_file(file_bytes, resume.filename)
        
        if not resume_text or len(resume_text.strip()) < 50:
            raise HTTPException(
                status_code=400,
                detail="Resume text is too short or empty. Please upload a valid resume."
            )
        
        # Perform analysis
        analysis_result = analyze_resume(resume_text, job_description)
        
        return analysis_result
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error processing resume: {str(e)}"
        )


# ==================== ERROR HANDLERS ====================

@app.exception_handler(404)
async def not_found_handler(request, exc):
    return {"error": "Endpoint not found", "status": 404}


@app.exception_handler(500)
async def internal_error_handler(request, exc):
    return {"error": "Internal server error", "status": 500}


# ==================== STARTUP ====================

if __name__ == "__main__":
    import uvicorn
    
    print("ðŸš€ Starting ResumeLens API Server...")
    print("ðŸ“ API Documentation: http://localhost:8000/docs")
    print("ðŸ” Interactive API: http://localhost:8000/redoc")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        reload=True
    )